{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-107403504",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "**把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非商業用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "\n",
        "!wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mbvzh_9_Tz8",
        "outputId": "09937972-2675-4afd-e37e-c3520c250020"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"/content/Qiong Yao.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"瓊瑤煙雨濛濛共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "瓊瑤煙雨濛濛共有 157411 字詞\n",
            "包含了 2815 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一六年十一月四日版》\n",
            "《好讀書櫃》經典版\n",
            "第一章\n",
            "又到了這可厭的日子，吃過了晚飯，我悶悶的坐在窗前的椅子裡，望著窗外那綿綿密密的細雨。屋檐下垂著的電線上，掛著一串水珠，晶瑩而透明，像一條珍珠項鍊。在那圍牆旁邊的芭蕉樹上，水滴正從那闊大的葉片上滾下來，一滴又一滴，單調而持續的滾落在泥地上。圍牆外面，一盞街燈在細雨裡高高的站著，漠然的放射著它那昏黃的光線，那麼的孤高和驕傲，好像全世界上的事與它無關似的。本來嘛，世界上的事與它又有什麼關係呢？我嘆了口氣，從椅子裡站了起來，無論如何，我該去辦自己的事了。\n",
            "「依萍，你還沒有去嗎？」\n",
            "媽從廚房裡跑了出來，她剛剛洗過碗，手上的水還沒有擦乾，那條藍色滾白邊的圍裙也還繫在她的腰上。\n",
            "「我就要去了。」我無可奈何的說，在屋角裡找尋我的雨傘。\n",
            "「到了『那邊』，不要和他們起衝突才好，告訴你爸爸，房租不能再拖了，我們已經欠了兩個月──」\n",
            "「我知道，不管用什麼方法，我把錢要來就是了！」我說，仍然在找尋我的傘。\n",
            "「你的傘在壁櫥裡。」媽說，從壁櫥裡拿出了我的傘，交給了我，又望了望天，低聲的說：「早一點回來，如果拿到了錢，就坐三輪車回來吧！雨要下大了。」\n",
            "我拿著傘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "8aaa716d-a534-4c47-a990-e5e8d5434513"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "去除次數小於8的文字剩餘 : 1331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "033d748d-2d77-4be9-fe12-9be62d197321"
      },
      "source": [
        "print(f\"原本煙雨濛濛共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本煙雨濛濛共有 157411 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘152829個字\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "13f81b42-8c55-43e3-9158-a16eb9686811"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原始文字 : \n",
            "['\\n', '《', '二', '一', '六', '年', '十', '一', '月', '四', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '經', '版', '\\n', '第', '一', '\\n', '又', '到', '了', '這', '可', '厭', '的', '日', '子', '，', '吃', '過', '了', '晚']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{1282, 1158, 1033, 1292, 1167, 1301, 1305, 539, 1307, 1060, 293, 938, 1322, 1326, 687, 688, 1327, 1328, 1330, 1209, 196, 197, 1094, 332, 983, 1004, 1262, 1139, 1268, 1276}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "d1ae32d4-e149-4928-f197-21e21ddaf6de"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[1326  687  938 1322  539 1167 1158 1322 1060 1033 1139  196  688 1326\n",
            "  687 1276  197 1292  332  688 1209], shape=(21,), dtype=int32)\n",
            "['\\n', '《', '二', '一', '六', '年', '十', '一', '月', '四', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '經']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[ 196 1326  983 1322 1326 1268 1305 1327 1307 1262  293 1328 1139 1301\n",
            " 1330 1094 1282 1327 1004  753 1330], shape=(21,), dtype=int32)\n",
            "['版', '\\n', '第', '一', '\\n', '又', '到', '了', '這', '可', '厭', '的', '日', '子', '，', '吃', '過', '了', '晚', '飯', '，']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "d649db09-860b-4d9a-8eb7-9e75b3f17f29"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "e5084e0c-4662-44d5-b47d-5b916da80740"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : ['\\n', '《', '二', '一', '六', '年', '十', '一', '月', '四', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》']\n",
            "Target: ['《', '二', '一', '六', '年', '十', '一', '月', '四', '日', '版', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '經']\n",
            "--------------------------------------------------\n",
            "Input : [1326  687  938 1322  539 1167 1158 1322 1060 1033 1139  196  688 1326\n",
            "  687 1276  197 1292  332  688]\n",
            "Target: [ 687  938 1322  539 1167 1158 1322 1060 1033 1139  196  688 1326  687\n",
            " 1276  197 1292  332  688 1209]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "90365ed8-395c-4318-d456-4071423822fc"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 20), (64, 20)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "eaff7e76-e963-494e-8a7a-cfb09daddc82"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 512)         681472    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 4096)        75513856  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, None, 2048)        50339840  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 1331)        2727219   \n",
            "=================================================================\n",
            "Total params: 129,262,387\n",
            "Trainable params: 129,262,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "1bc4b352-a958-47b8-a112-82996406a826"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 1331)\n",
            "Model target shape : (64, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "d98e786b-a033-4410-8db6-c5762f933cbe"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "了，謝謝老天！」她興奮的去端那杯牛，又要\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "秘蹙蹙蹙眉眉拚挨眉由由由修修修顯顯顯拚取\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "76094a1b-162e-4a10-c1a6-1f82645a5b0c"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "113/113 [==============================] - 40s 328ms/step - loss: 6.1959\n",
            "Epoch 2/20\n",
            "113/113 [==============================] - 39s 342ms/step - loss: 5.3163\n",
            "Epoch 3/20\n",
            "113/113 [==============================] - 41s 358ms/step - loss: 4.5809\n",
            "Epoch 4/20\n",
            "113/113 [==============================] - 42s 366ms/step - loss: 4.0697\n",
            "Epoch 5/20\n",
            "113/113 [==============================] - 41s 365ms/step - loss: 3.7171\n",
            "Epoch 6/20\n",
            "113/113 [==============================] - 43s 376ms/step - loss: 3.4025\n",
            "Epoch 7/20\n",
            "113/113 [==============================] - 43s 378ms/step - loss: 3.0290\n",
            "Epoch 8/20\n",
            "113/113 [==============================] - 43s 380ms/step - loss: 2.5888\n",
            "Epoch 9/20\n",
            "113/113 [==============================] - 43s 383ms/step - loss: 2.0344\n",
            "Epoch 10/20\n",
            "113/113 [==============================] - 43s 383ms/step - loss: 1.4265\n",
            "Epoch 11/20\n",
            "113/113 [==============================] - 43s 380ms/step - loss: 0.8948\n",
            "Epoch 12/20\n",
            "113/113 [==============================] - 43s 381ms/step - loss: 0.5241\n",
            "Epoch 13/20\n",
            "113/113 [==============================] - 43s 383ms/step - loss: 0.3547\n",
            "Epoch 14/20\n",
            "113/113 [==============================] - 43s 380ms/step - loss: 0.2945\n",
            "Epoch 15/20\n",
            "113/113 [==============================] - 43s 379ms/step - loss: 0.2698\n",
            "Epoch 16/20\n",
            "113/113 [==============================] - 43s 380ms/step - loss: 0.2566\n",
            "Epoch 17/20\n",
            "113/113 [==============================] - 43s 382ms/step - loss: 0.2466\n",
            "Epoch 18/20\n",
            "113/113 [==============================] - 43s 383ms/step - loss: 0.2407\n",
            "Epoch 19/20\n",
            "113/113 [==============================] - 43s 383ms/step - loss: 0.2359\n",
            "Epoch 20/20\n",
            "113/113 [==============================] - 44s 384ms/step - loss: 0.2309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "65a3102f-abcf-4b29-a8cf-f385517126a1"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3elbMNg4z4N",
        "outputId": "6c2b23de-9613-4fe1-e995-6d46ce872e44"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "了，謝謝老天！」她興奮的去端那杯牛，又要\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "，他謝老天！」她興奮的去端那杯牛，又要笑\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050ccd08-e30b-49ed-d933-6550cd24dbd7"
      },
      "source": [
        "init_seq = \"煙雨濛濛\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "煙雨濛濛的走了出去。我在客廳裡坐了下來，立即，四週之後，我們才能吐出一口氣。\n",
            "書桓在我身邊，我轉過頭，看到我回頭。她扭著身子，露出一口煙和惶惑的，又又一次又一次。這時，我們的同學，只是我們喪中都是個鬼，可是，我腦子中越來越沉重，幾次越氣越氣，氣不得像一個我的。爸爸，他在我的眼前和仇恨他的東西，是個望見的！」\n",
            "「我想先查媽，」我說：「我一點都沒有不寧了。」\n",
            "「你懷疑我──」雪姨大聲的喊。\n",
            "「那麼，你幫我去就是我，我是個沒有人性的女兒！」\n",
            "「雪姨！」爸爸興奮的插了進來說：「你想要！我要讓你死！」\n",
            "「我不是！」他們繼續走了一段，方瑜說：「你是不是需要一個助理？」\n",
            "「我不做你！」他笑著說：「我也不知道你來了，你要我們一起，給我一個意外！」\n",
            "「你是嗎？」我有點氣憤：「你認為我是個危嗎？」\n",
            "「是的，在金錢方面很貧窮，在人母親，」在一個小包車前面，我的手從沙發中抬起來，他的眼睛哀傷而淒苦。我望著他，於是，他又張開眼睛來看看我，低聲的說：「你再多說也沒用，你要就把錢，我不是再在你的腳頭了！」\n",
            "「哦，我的天！」我嘆口氣。「那麼，你斷定有個外來的共謀犯，是人、夢萍、夢萍、夢萍，我們再重新認識，重新戀愛多好！」這是"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "source": [
        "import time\n",
        "while True:\n",
        "  time.sleep(5)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}